{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning File in Airflow SaaS in Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Astronomer Airflow SaaS limits total memory in each task, so its best to use s3 streams when working with in memory tranforms.\n",
    "\n",
    "### Note: This might not apply for smaller files, as basic transforms can be done in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import smart_open\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from airflow.operators import PythonOperator, DummyOperator, PostgresOperator\n",
    "from airflow.hooks.S3_hook import S3Hook\n",
    "\n",
    "def ftp_unzip_s3(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Unzips a file from an FTP to s3. Uses BytesIO and zipfile to stream files of variable size into s3.\n",
    "    \n",
    "    This function is meant to be called as a Python Callable in Airflow.\n",
    "    \n",
    "    The output in S3 are the indvidual files within the original zipfile.  \n",
    "    \"\"\"\n",
    "\n",
    "    file_name = 'astronomer_extract'\n",
    "\n",
    "    url = ('FTP_URl_{0}'.\n",
    "           format(file_name))\n",
    "\n",
    "    req = urllib.request.urlretrieve(url, file_name)\n",
    "    s3 = S3Hook(s3_conn_id=s3_conn_id)\n",
    "    s3_creds = s3.get_connection(s3_conn_id).extra_dejson\n",
    "\n",
    "    # Read the file\n",
    "    with io.BytesIO() as b:\n",
    "        b = open(file_name, \"rb\")\n",
    "        b.seek(0)\n",
    "        with zipfile.ZipFile(b, mode='r') as zipf:\n",
    "            for subfile in zipf.namelist():\n",
    "                file_name = 'astronomer_extract_' + subfile\n",
    "                s3_key = '{}/{}'.format(\n",
    "                    s3_bucket,\n",
    "                    file_name\n",
    "                )\n",
    "                print(file_name)\n",
    "                url = 's3://{}:{}@{}'.format(\n",
    "                    s3_creds['aws_access_key_id'],\n",
    "                    s3_creds['aws_secret_access_key'],\n",
    "                    s3_key)\n",
    "                with smart_open.smart_open(url, 'wb') as fout:\n",
    "                    info = zipf.open(subfile)\n",
    "                    for line in info:\n",
    "                        info = (line)\n",
    "                        fout.write(info)\n",
    "\n",
    "                logging.info(\"Uploaded file!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
